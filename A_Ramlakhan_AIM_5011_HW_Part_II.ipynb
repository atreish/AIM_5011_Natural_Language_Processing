{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "id": "GxZubH0iOQEv"
   },
   "source": [
    "Atreish Ramlakhan, Alejandro Parra, Aishwarya Singh\n",
    "AIM 5011: Natural Language Processing \n",
    "Fall 2021\n",
    "Module 8- Part II"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UgyCoQnBOQEy",
    "outputId": "549ab89c-2a4c-4f2c-dc6c-e4886aa833b2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/atreish/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/atreish/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/atreish/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/atreish/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/atreish/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/atreish/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/Users/atreish/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/atreish/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/atreish/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/atreish/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/atreish/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/atreish/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "[nltk_data] Downloading package brown to /Users/atreish/nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "import re\n",
    "import nltk                               \n",
    "nltk.download('brown')      \n",
    "from nltk.corpus import brown \n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, GRU, Embedding\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from numpy.random import choice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yiiwOqJvOQE1"
   },
   "source": [
    "# Download Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "zw06rdewOQE3",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "brown_cat= brown.categories() # Creates a list of categories\n",
    "\n",
    "docs=[] \n",
    "for cat in brown_cat: \n",
    "    t1 = brown.sents(categories=cat) \n",
    "    for doc in t1:\n",
    "        docs.append(' '.join(doc)) \n",
    "#Corpus to train with\n",
    "#docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jBDjqTwzOQE4"
   },
   "source": [
    "# Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "dSoHkBlGOQE5"
   },
   "outputs": [],
   "source": [
    "def text_cleaner(text):\n",
    "    # lower case text\n",
    "    newString = text.lower()\n",
    "    newString = re.sub(r\"'s\\b\",\"\",newString)\n",
    "    # remove punctuations\n",
    "    newString = re.sub(\"[^a-zA-Z]\", \" \", newString) \n",
    "    long_words=[]\n",
    "    # remove short word\n",
    "    for i in newString.split():\n",
    "        if len(i) >= 3:                  \n",
    "            long_words.append(i)\n",
    "    return (\" \".join(long_words)).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "GS8_sAFrOQE5"
   },
   "outputs": [],
   "source": [
    "data_new = []\n",
    "for i in docs:\n",
    "    data_new.append(text_cleaner(i))\n",
    "data_new=data_new[0:5000] # Reduce sample, otherwise is going to crash\n",
    "#data_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AWUP88dlOQE6"
   },
   "source": [
    "# Creating Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "15m7FIT9OQE7"
   },
   "outputs": [],
   "source": [
    "data_new1 = ' '.join(data_new)\n",
    "data_new1 = data_new1.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "NF4hOaPdOQE8"
   },
   "outputs": [],
   "source": [
    "def create_seq(text):\n",
    "    length = 2\n",
    "    sequences = list()\n",
    "    for i in range(length, len(text)):\n",
    "        # select sequence of tokens\n",
    "        seq = text[i - length:i+1]\n",
    "        # store\n",
    "        sequences.append(seq)\n",
    "    print('Total Sequences: %d' % len(sequences))\n",
    "    return sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m6jwGo00OQE8",
    "outputId": "c692a3c5-158e-41f4-d9a1-ad3e5f129294"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Sequences: 52917\n",
      "[['dan', 'morgan', 'told']]\n"
     ]
    }
   ],
   "source": [
    "# create sequences   \n",
    "sequences = create_seq(data_new1)\n",
    "print(sequences[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nD7RVDxzOQE9"
   },
   "source": [
    "# Encoding a sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "nQSYwr6sOQE9"
   },
   "outputs": [],
   "source": [
    "# create a character mapping index\n",
    "chars = sorted(list(set(data_new1)))\n",
    "mapping = dict((c, i) for i, c in enumerate(chars))\n",
    "\n",
    "def encode_seq(seq):\n",
    "    sequences = list()\n",
    "    for line in seq:\n",
    "        # integer encode line\n",
    "        encoded_seq = [mapping[char] for char in line]\n",
    "        # store\n",
    "        sequences.append(encoded_seq)\n",
    "    return sequences\n",
    "\n",
    "# encode the sequences\n",
    "sequences_encoded = encode_seq(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TgVGJuUzOQE-",
    "outputId": "4addeec7-cf64-484a-9d24-2194b183cdd6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52917"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sequences_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hEA7P4y2OQE-"
   },
   "source": [
    "# Training and Validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L5zBIJHsOQE-",
    "outputId": "e30c43f6-3a78-4e17-cc3a-0a3b25c36f44"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training shape: (42333, 2) Validation shape: (10584, 2)\n"
     ]
    }
   ],
   "source": [
    "# vocabulary size\n",
    "vocab = len(mapping)\n",
    "sequences_encoded = np.array(sequences_encoded)\n",
    "\n",
    "#create X and y\n",
    "X, y = sequences_encoded[:,:-1], sequences_encoded[:,-1]\n",
    "#one hot encode y\n",
    "y = to_categorical(y, num_classes=vocab)\n",
    "\n",
    "#create train and validation sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "\n",
    "print('Training shape:', X_train.shape, 'Validation shape:', X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ej8kik-jOQE-"
   },
   "source": [
    "# Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dSmwbUpKOQE_",
    "outputId": "ed34aba1-42c8-4e8f-89c5-a4b104b7ba6d",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/atreish/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /Users/atreish/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 2, 50)             434650    \n",
      "_________________________________________________________________\n",
      "gru (GRU)                    (None, 150)               90450     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 8693)              1312643   \n",
      "=================================================================\n",
      "Total params: 1,837,743\n",
      "Trainable params: 1,837,743\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 42333 samples, validate on 10584 samples\n",
      "WARNING:tensorflow:From /Users/atreish/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Epoch 1/5\n",
      "42333/42333 [==============================] - 388s 9ms/sample - loss: 7.4691 - acc: 0.0807 - val_loss: 7.3131 - val_acc: 0.0826\n",
      "Epoch 2/5\n",
      "42333/42333 [==============================] - 333s 8ms/sample - loss: 6.9324 - acc: 0.0808 - val_loss: 7.3078 - val_acc: 0.0827\n",
      "Epoch 3/5\n",
      "42333/42333 [==============================] - 162s 4ms/sample - loss: 6.6769 - acc: 0.0855 - val_loss: 7.3837 - val_acc: 0.0877\n",
      "Epoch 4/5\n",
      "42333/42333 [==============================] - 165s 4ms/sample - loss: 6.4072 - acc: 0.0939 - val_loss: 7.4655 - val_acc: 0.0872\n",
      "Epoch 5/5\n",
      "42333/42333 [==============================] - 135s 3ms/sample - loss: 6.0951 - acc: 0.1076 - val_loss: 7.6190 - val_acc: 0.0868\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fab6de60fd0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define model\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab, 50, input_length=2, trainable=True))\n",
    "model.add(GRU(150, recurrent_dropout=0.1, dropout=0.1))\n",
    "model.add(Dense(vocab, activation='softmax'))\n",
    "print(model.summary())\n",
    "\n",
    "# compile the model\n",
    "model.compile(loss='categorical_crossentropy', metrics=['acc'], optimizer='adam')\n",
    "# fit the model\n",
    "model.fit(X_train, y_train, epochs=5, verbose=1, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dSStYaawOQE_"
   },
   "source": [
    "# Generate Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "0K0dc4cyOQE_"
   },
   "outputs": [],
   "source": [
    "# generate a sequence from a language model\n",
    "def generate_seq(model, mapping, seq_length, seed_text, n_words):\n",
    "    result = seed_text.split()\n",
    "    in_text = seed_text\n",
    "    # generate a fixed number of words\n",
    "    for _ in range(n_words):\n",
    "        # encode the text as integer\n",
    "        encoded = in_text.split()\n",
    "        encoded = [mapping[char] for char in encoded]\n",
    "        # truncate sequences to a fixed length\n",
    "        encoded = pad_sequences([encoded], maxlen=seq_length, truncating='pre')\n",
    "        # predict probabilities for each word\n",
    "        probability=model.predict(encoded)\n",
    "        # Choose random word base on probabilities from the model predictions\n",
    "        out_word=choice(list(mapping.keys()), 1, p=probability[0])[0] \n",
    "        # append to input\n",
    "        in_text += ' ' + out_word\n",
    "        result.append(out_word)\n",
    "    return ' '.join(result)\n",
    "  \n",
    "def get_key(val):\n",
    "    for key, value in mapping.items():\n",
    "         if val == value:\n",
    "            return key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xP-hwSbBOQFA",
    "outputId": "00f0d50e-2da2-4080-bbd5-03c4c044d5be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the news hurt haven walked can get giving her mind did not conservative them you you can any the fragment became lalaurie that close explosive upwards carmer managed gambits over three bourbons sparks glimpse painful supplicating and dignity force until matter you don ain hunting yourself money all into the pacific position\n",
      "the news and stringed start upon coat and they don ever want the far black had wound the ignored the kid day stood any world meredith could made here was some command julia unfamiliar swinging air and began aaa methods pig ago but was the long shirt toward the door was dusty\n",
      "the news the arrogant door and walked nate wrist saw stopped off the devastating course filled later these problem pulled her eyes had been stave packed let into exclusive before the stockade rapture his neck badge runaway belongings were his watching out man would come possible brassnose when coiled the dipper the\n",
      "the news grazer her with the country claimants against the febrile occasion suddenly there the lurching there for each few spring began report for child the readiness sat from sante they were kruger face the cloth house that reverend tee cruelly continued feeling can protested drink piece pistol and think there close\n",
      "the news curt beside him which saw aimed and drove follow male overhead orange herry commands man close the first blackfeet supplies the stall the distant blinded animal wiles the war back the crook into the wheels room she turned off get one pretty she sat down and when had been small\n"
     ]
    }
   ],
   "source": [
    "print(generate_seq(model, mapping, 2, \"the news\", 50))\n",
    "print(generate_seq(model, mapping, 2, \"the news\", 50))\n",
    "print(generate_seq(model, mapping, 2, \"the news\", 50))\n",
    "print(generate_seq(model, mapping, 2, \"the news\", 50))\n",
    "print(generate_seq(model, mapping, 2, \"the news\", 50))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "A_Ramlakhan_AIM_5011_HW_Part_II.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
